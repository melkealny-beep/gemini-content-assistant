
import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, HarmBlockThreshold, HarmCategory
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain_core.output_parsers import StrOutputParser

# --- Security Best Practice: Get API Key from .env file ---
load_dotenv()

# Check if the API key is available
if "GOOGLE_API_KEY" not in os.environ:
    print("ğŸš¨ Error: GOOGLE_API_KEY environment variable not set.")
    print("Please create a .env file and set your API key to run this script.")
    exit()

# --- Initialize the LLM ---
# Using a newer, widely available model to ensure compatibility.
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash-latest",
    convert_system_message_to_human=True,
    safety_settings={
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    },
)

# --- Initialize the Vision LLM ---
# The same modern model can handle both text and vision.
vision_llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash-latest",
    safety_settings={
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    },
)


def generate_post_idea():
    """Generates a new post idea using the LangChain and Gemini API."""
    try:
        print("âœ¨ Ù…Ø±Ø­Ø¨Ù‹Ø§ Ø¨Ùƒ ÙÙŠ Ù…ÙˆÙ„Ø¯ Ø£ÙÙƒØ§Ø± Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª!")
        print("---")
        topic = input("ğŸ¤” Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø°ÙŠ ÙŠØ¯ÙˆØ± ÙÙŠ Ø°Ù‡Ù†ÙƒØŸ (Ù…Ø«Ø§Ù„: ØªØ³ÙˆÙŠÙ‚ Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰) ")
        platform = input("ğŸ¯ Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ù†ØµØ© Ø§Ù„ØªÙŠ Ø³ØªÙ†Ø´Ø± Ø¹Ù„ÙŠÙ‡Ø§ØŸ (Ù…Ø«Ø§Ù„: Ù…Ø¯ÙˆÙ†Ø©, ØªÙˆÙŠØªØ±, Ø§Ù†Ø³ØªØºØ±Ø§Ù…) ")
        goal = input("ğŸš€ Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ù‡Ø¯Ù Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†Ø´ÙˆØ±ØŸ (Ù…Ø«Ø§Ù„: Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙˆØ¹ÙŠ, Ø¬Ø°Ø¨ Ø¹Ù…Ù„Ø§Ø¡) ")

        # --- Create the Prompt ---
        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content="Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø¨ÙŠØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø£ÙÙƒØ§Ø± Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø¹Ù„Ù‰ ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ."),
            HumanMessagePromptTemplate.from_template("Ø£Ø±ÙŠØ¯ ÙÙƒØ±Ø© Ù…Ù†Ø´ÙˆØ± Ø­ÙˆÙ„ '{topic}' Ù„Ù…Ù†ØµØ© '{platform}'. Ø§Ù„Ù‡Ø¯Ù Ù‡Ùˆ '{goal}'. Ø§Ù‚ØªØ±Ø­ ÙÙƒØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ø¨ØªÙƒØ±Ø© ÙˆØ¬Ø°Ø§Ø¨Ø©."),
        ])

        # --- Create the Chain ---
        chain = prompt | llm | StrOutputParser()

        print("\nğŸ¤– Ø­Ø³Ù†Ù‹Ø§! Ø£ÙÙƒØ± ÙÙŠ ÙÙƒØ±Ø© Ø±Ø§Ø¦Ø¹Ø© Ù„Ùƒ...\n")

        # --- Invoke the Chain ---
        response = chain.invoke({"topic": topic, "platform": platform, "goal": goal})

        print("ğŸ‰ ÙÙƒØ±ØªÙƒ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ù…Ù†Ø´ÙˆØ± ğŸ‰")
        print("---")
        print(response)
        print("---separated_spec---")

    except Exception as e:
        print(f"ğŸ˜­ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")


def generate_caption_for_image():
    """Generates a caption for an image using LangChain and the Gemini Vision API."""
    import base64
    import io
    from PIL import Image

    try:
        print("âœ¨ Ù…Ø±Ø­Ø¨Ù‹Ø§ Ø¨Ùƒ ÙÙŠ Ù…ÙˆÙ„Ø¯ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±!")
        print("---")
        
        image_path = input("ğŸ–¼ï¸ Ù…Ù† ÙØ¶Ù„Ùƒ Ø£Ø¯Ø®Ù„ Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ ØµÙˆØ±ØªÙƒ: ")
        if not os.path.exists(image_path):
            print("âŒ Ø¹Ø°Ø±Ù‹Ø§, Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³Ø§Ø±.")
            return

        try:
            # Function to encode the image
            def encode_image(image_path):
                with open(image_path, "rb") as image_file:
                    return base64.b64encode(image_file.read()).decode('utf-8')

            base64_image = encode_image(image_path)
        except Exception as e:
            print(f"âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† ÙØªØ­ Ø£Ùˆ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø±: {image_path}. ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡ Ù…Ù„Ù ØµÙˆØ±Ø© ØµØ§Ù„Ø­. Ø§Ù„Ø®Ø·Ø£: {e}")
            return
        
        caption_goal = input("ğŸš€ Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ù‡Ø¯Ù Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ØŸ (Ù…Ø«Ø§Ù„: Ø¨ÙŠØ¹ Ù…Ù†ØªØ¬, Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙØ§Ø¹Ù„) ")
        tone = input("ğŸ­ Ù…Ø§ Ù‡ÙŠ Ù†Ø¨Ø±Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ØŸ (Ù…Ø«Ø§Ù„: ÙˆØ¯ÙˆØ¯, Ø§Ø­ØªØ±Ø§ÙÙŠ, ÙÙƒØ§Ù‡ÙŠ) ")
        
        # --- Create the Message ---
        message = HumanMessage(
            content=[
                {
                    "type": "text",
                    "text": f"Ø§ÙƒØªØ¨ ØªØ¹Ù„ÙŠÙ‚Ù‹Ø§ Ù„Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©. Ø§Ù„Ù‡Ø¯Ù Ù‡Ùˆ '{caption_goal}' ÙˆØ§Ù„Ù†Ø¨Ø±Ø© ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† '{tone}'. Ø£Ø¶Ù Ù‡Ø§Ø´ØªØ§Ù‚Ø§Øª Ø°Ø§Øª ØµÙ„Ø©.",
                },
                {"type": "image_url", "image_url": f"data:image/jpeg;base64,{base64_image}"},
            ]
        )

        print("\nğŸ¤– Ø­Ø³Ù†Ù‹Ø§! Ø£Ù‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙˆÙƒØªØ§Ø¨Ø© ØªØ¹Ù„ÙŠÙ‚...\n")

        # --- Invoke the Model ---
        response = vision_llm.invoke([message])

        print("ğŸ‰ ØªØ¹Ù„ÙŠÙ‚Ùƒ Ø§Ù„Ø¬Ø¯ÙŠØ¯ ğŸ‰")
        print("---")
        print(response.content)
        print("---separated_spec---")

    except Exception as e:
        print(f"ğŸ˜­ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")


def main():
    """The main function of the content assistant."""
    print("ğŸ‘‹ Ù…Ø±Ø­Ø¨Ù‹Ø§ Ø¨Ùƒ ÙÙŠ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ!")
    print("Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ø±Ø§Ø¦Ø¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini.")

    while True:
        print("\n--- Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---")
        print("1. ğŸ’¡ Ø¥Ù†Ø´Ø§Ø¡ ÙÙƒØ±Ø© Ù…Ù†Ø´ÙˆØ± Ø¬Ø¯ÙŠØ¯Ø©")
        print("2. ğŸ“¸ Ø¥Ù†Ø´Ø§Ø¡ ØªØ¹Ù„ÙŠÙ‚ Ø¹Ù„Ù‰ ØµÙˆØ±Ø©")
        print("3. ğŸ‘‹ Ø§Ù„Ø®Ø±ÙˆØ¬")
        
        choice = input("ğŸ”§ Ù…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ Ø£Ù† ØªÙØ¹Ù„ØŸ (Ø§Ø®ØªØ± 1, 2, Ø£Ùˆ 3): ")

        if choice == '1':
            generate_post_idea()
        elif choice == '2':
            generate_caption_for_image()
        elif choice == '3':
            print("ğŸ‘‹ Ù…Ø¹ Ø§Ù„Ø³Ù„Ø§Ù…Ø©!")
            break
        else:
            print("âŒ Ø§Ø®ØªÙŠØ§Ø± Ø®Ø§Ø·Ø¦. Ù…Ù† ÙØ¶Ù„Ùƒ Ø§Ø®ØªØ± 1, 2, Ø£Ùˆ 3.")

if __name__ == "__main__":
    main()
